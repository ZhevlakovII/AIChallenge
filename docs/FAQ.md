# Часто задаваемые вопросы (FAQ)

## 1. Как работает чат с LLM?

Функция чата использует клиент-серверную архитектуру для взаимодействия с большими языковыми моделями (LLM). Когда вы отправляете сообщение:

1. Ваше сообщение отправляется на настроенный провайдер LLM (OpenAI, Anthropic, локальная модель и т.д.)
2. Приложение включает историю разговора в качестве контекста
3. LLM обрабатывает ваш запрос и генерирует ответ
4. Ответ передается обратно в интерфейс чата в режиме реального времени

Чат поддерживает несколько потоков разговора, историю сообщений и контекстно-зависимые ответы.

## 2. Какие настройки доступны для LLM?

Приложение предоставляет следующие настраиваемые параметры для провайдеров LLM:

- **API_KEY**: Ключ аутентификации для доступа к API провайдера LLM
- **baseUrl**: URL-адрес конечной точки для сервиса LLM (например, `https://api.openai.com/v1`)
- **model**: Конкретная модель для использования (например, `gpt-4`, `claude-3-opus`, `llama-3.1-8b`)
- **topK**: Управляет разнообразием ответов, ограничивая количество рассматриваемых токенов с наивысшей вероятностью (по умолчанию: 40)

## 3. Откуда берутся значения этих настроек?

Все настройки конфигурации LLM хранятся локально на вашем устройстве:

- **Android**: Приватное хранилище приложения с использованием DataStore Preferences
- **Desktop (JVM)**: Локальные конфигурационные файлы в директории данных приложения
- **Доступ к настройкам**: Перейдите в Настройки → Конфигурация LLM для просмотра и изменения этих значений

Ваши API-ключи и учетные данные никогда не отправляются третьим лицам, кроме настроенного провайдера LLM.

## 4. Что делать, если модель не отвечает?

Если вы не получаете ответы от LLM, проверьте следующее:

**Проблемы с сетью:**
- Убедитесь, что ваше интернет-соединение стабильно
- Проверьте, доступен ли baseUrl (попробуйте открыть его в браузере)
- Убедитесь, что ваш брандмауэр не блокирует соединение

**Проблемы с конфигурацией:**
- Проверьте, что ваш API_KEY действителен и не истек
- Подтвердите, что baseUrl правильный для вашего провайдера
- Убедитесь, что выбранная модель доступна с вашим API-ключом

**Проблемы с таймаутом:**
- Некоторые модели могут дольше отвечать на сложные запросы
- Попробуйте сначала с более коротким, простым запросом
- Рассмотрите возможность увеличения таймаута в расширенных настройках

## 5. Типичная проблема: Неправильный API-ключ

**Симптомы:**
- Ошибка "Аутентификация не удалась" или "401 Unauthorized"
- Сообщение "Недействительный API-ключ"

**Решения:**
1. Тщательно проверьте ваш API_KEY на опечатки (они часто содержат специальные символы)
2. Убедитесь, что ключ не истек в панели управления вашего провайдера
3. Убедитесь, что вы используете правильный ключ для выбранного провайдера
4. Попробуйте сгенерировать новый API-ключ на сайте вашего провайдера

## 6. Типичная проблема: Неверный URL

**Симптомы:**
- Ошибка "Connection refused" или "404 Not Found"
- Сообщение "Невозможно достичь сервера"

**Решения:**
1. Проверьте, что формат baseUrl включает протокол (https://)
2. Распространенные URL:
   - OpenAI: `https://api.openai.com/v1`
   - Anthropic: `https://api.anthropic.com/v1`
   - Локальный Ollama: `http://localhost:11434`
3. Удалите завершающие слэши из URL
4. Проверьте документацию провайдера на предмет правильной конечной точки

## 7. Типичная проблема: Модель не найдена

**Симптомы:**
- Ошибка "Model not found" или "404"
- Сообщение "Модель `xyz` не существует"

**Решения:**
1. Убедитесь, что имя модели написано правильно (с учетом регистра)
2. Проверьте, имеет ли ваш API-ключ доступ к этой модели
3. Посетите документацию вашего провайдера для доступных моделей
4. Некоторые модели требуют специального доступа или подписки более высокого уровня
5. Попробуйте использовать другую, широко доступную модель:
   - OpenAI: `gpt-3.5-turbo`, `gpt-4`
   - Anthropic: `claude-3-sonnet-20240229`

## 8. Типичная проблема: Слишком большое значение topK

**Симптомы:**
- Низкое качество или бессвязные ответы
- Неожиданные или случайные выходные данные
- Ошибки "Недействительный параметр"

**Решения:**
1. Сбросьте topK до значения по умолчанию (40)
2. Рекомендуемые диапазоны:
   - Низкий (10-20): Более целенаправленные, детерминированные ответы
   - Средний (30-50): Сбалансированная креативность и связность
   - Высокий (60-100): Более разнообразные, но потенциально менее связные
3. Если вы видите ошибки "Недействительный параметр", ваш провайдер может не поддерживать topK
4. Не все модели поддерживают параметр topK - проверьте документацию вашего провайдера
